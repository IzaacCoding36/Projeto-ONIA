[![Typing SVG](https://readme-typing-svg.herokuapp.com?font=Orbitron&weight=500&size=17&pause=1000&color=FFFFFF&background=0B004B&center=true&vCenter=true&width=1000&height=100&lines=Primeira+Olimp%C3%ADada+Nacional+de+Intelig%C3%AAncia+Artificial;ONIA;Projeto+Finalista)](https://git.io/typing-svg)

---

# Projeto ONIA

Esse reposit√≥rio ser√° utilizado para a publica√ß√£o e desenvolvimento do meu projeto para a primeira Olimp√≠ada Nacional de Intelig√™ncia Artificial (ONIA) de 2025.

## üìã Estrutura do Projeto

- `modelo-xgb-classifier.py` - Script principal original
- `modelo_xgb_classifier_v2.py` - Vers√£o melhorada e modular
- `train.py` - Script de treinamento com configura√ß√µes flex√≠veis
- `checagem.py` - Script de verifica√ß√£o de resultados
- `config.py` - Arquivo de configura√ß√µes
- `requirements.txt` - Depend√™ncias do projeto
- `templates/` - Dados de treino e teste

## üöÄ Como Usar

### Instala√ß√£o das Depend√™ncias
```bash
pip install -r requirements.txt
```

### Execu√ß√£o Simples
```bash
# Usar configura√ß√µes padr√£o
python modelo_xgb_classifier_v2.py

# Ou usar o script original melhorado
python modelo-xgb-classifier.py
```

### Execu√ß√£o com Configura√ß√µes Personalizadas
```bash
# Exemplo com par√¢metros diferentes
python train.py --n-estimators 1000 --max-depth 15 --learning-rate 0.05

# Sem normaliza√ß√£o dos dados
python train.py --no-scaling

# Usando valida√ß√£o de 20%
python train.py --validation-size 0.2
```

### Verifica√ß√£o dos Resultados
```bash
python checagem.py
```

## üîß Melhorias Implementadas

### ‚úÖ Portabilidade
- Removidos caminhos hardcodados
- Suporte a diferentes diret√≥rios de dados
- Compatibilidade com diferentes sistemas operacionais

### ‚úÖ Tratamento de Erros
- Valida√ß√£o de entrada de dados
- Tratamento de exce√ß√µes robusto
- Mensagens de erro informativas

### ‚úÖ Logging e Monitoramento
- Sistema de logging detalhado
- Relat√≥rios de progresso em tempo real
- M√©tricas de desempenho detalhadas

### ‚úÖ Configura√ß√£o Flex√≠vel
- Arquivo de configura√ß√£o centralizado
- Par√¢metros customiz√°veis via linha de comando
- Diferentes op√ß√µes de normaliza√ß√£o

### ‚úÖ C√≥digo Modular
- Fun√ß√µes bem organizadas e reutiliz√°veis
- Separa√ß√£o de responsabilidades
- Documenta√ß√£o inline completa

### ‚úÖ Verifica√ß√£o Aprimorada
- Script de verifica√ß√£o robusto
- Valida√ß√£o de estrutura de dados
- Estat√≠sticas detalhadas dos resultados

## üìä No que se baseia esse projeto?

- Esse projeto baseia-se no treinamento de um modelo de classifica√ß√£o de dados para aprendizagem de m√°quina com algor√≠tmos. Onde temos dois arquivos com dados .csv para treinar o modelo de algor√≠tmo e trazer previs√µes de resultados com precis√£o calculada em Medida-F.
- Isso pode ser feito com v√°rios modelos de classifica√ß√£o, como DecisionTree, RandomForest, K-Nearest Neighbours, Na√Øve Bayes, Support Vector Machine e o XGBoost, geralmente usado em competi√ß√µes.
- A Medida-F √© a m√©dia harm√¥nica entre as m√©tricas de Precis√£o e Revoca√ß√£o. Em outras palavras, a Medida-F √© uma m√©trica que avalia o desempenho de um modelo preditivo de modo a trazer um n√∫mero √∫nico que indique a sua qualidade geral.
- Todos esses conceitos s√£o aplicados em um c√≥digo python, com os softwares Scikit-Learn ou Orange, com bibliotecas diversificadas para aprendizado de m√°quina.
- O objetivo de tudo isso √© poder treinar um modelo que apresente resultados com um excelente desempenho, medido na medida-f entre 0 e 1, quanto maior for o resultado da medida-f, mais pr√≥ximo da resposta ver√≠dica o seu resultado estar√°.

## üéØ Resultados Obtidos

**Medida-F**: ~0.78-0.79 (79% de precis√£o geral)

**Distribui√ß√£o das Classes Previstas**:
- Classe 0: ~55% das amostras
- Classe 1: ~14% das amostras  
- Classe 2: ~12% das amostras
- Classe 3: ~5% das amostras
- Classe 4: ~13% das amostras

## üìà Algoritmo Escolhido: XGBoost

Escolhi o XGBoost por sua precis√£o em corrigir erros iterativamente. Usei normaliza√ß√£o e ajustes para maximizar o desempenho nas 13 features, necess√°rio para ter um resultado com maior precis√£o para lidar com dados complexos como os fornecidos para essa fase.

**Par√¢metros Utilizados**:
- `n_estimators`: 500 √°rvores
- `max_depth`: 20 (profundidade m√°xima)
- `learning_rate`: 0.1 (taxa de aprendizado)
- Normaliza√ß√£o com `StandardScaler`
- Valida√ß√£o estratificada 90%/10%
